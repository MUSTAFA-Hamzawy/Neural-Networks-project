{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import joblib\n",
    "import csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import skimage.feature as ft\n",
    "from sklearn import metrics\n",
    "from commonFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shadow_removalDialate(img):\n",
    "    # img2 = cv2.imread(f'../Dataset_0-5/men/{num}/4_men (49).JPG')\n",
    "    img2 = cv2.resize(img, (256, 256))\n",
    "    \n",
    "    img_hls = cv2.cvtColor(img2, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "    # define lower and upper bounds for blue color in HLS format\n",
    "    lower_blue = np.array([0, 0, 60])\n",
    "    upper_blue = np.array([20, 255, 255])\n",
    "    # create a mask for blue color in HLS format\n",
    "    mask = cv2.inRange(img_hls, lower_blue, upper_blue)\n",
    "    # daialation\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    mask = cv2.dilate(mask,kernel,iterations = 8)\n",
    "    # apply the mask to the original image\n",
    "    result = cv2.bitwise_and(img2, img2, mask=mask)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img,img2):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply histogram equalization to enhance contrast and remove lighting effects\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    # io.imshow(equalized)\n",
    "    # # Find the contours of the binary image\n",
    "    contours, hierarchy = cv2.findContours(equalized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # # Draw the largest contour on the original image\n",
    "    cv2.drawContours(img2, [max_contour], 0, (0, 255, 0), 2)\n",
    "    # io.imshow(img2)\n",
    "    # # Show the image with the largest contour drawn\n",
    "    # # Create a bounding box around the hand\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "\n",
    "    # # Crop the image to the bounding box around the hand\n",
    "    hand = equalized[y:y+h, x:x+w]\n",
    "    # added \n",
    "    Noise_Reduction = cv2.medianBlur(hand, 5)\n",
    "    img3 = cv2.resize(Noise_Reduction, (256, 256))\n",
    "    # io.imshow(img3)\n",
    "\n",
    "    return img3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "arr = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "data=[]\n",
    "hog_features = []\n",
    "lower_blue = np.array([0, 0, 65])\n",
    "upper_blue = np.array([20, 255, 255])\n",
    "\n",
    "\n",
    "for label in arr:\n",
    "    dirList = glob.glob(\"../Dataset_0-5/men/\"+str(label)+\"/*.jpg\")\n",
    "    \n",
    "    for img_path in dirList:\n",
    "        try:\n",
    "            im= cv2.imread(img_path)\n",
    "            img = cv2.resize(im, (256,256))\n",
    "\n",
    "            result_image=shadow_removalDialate(img)\n",
    "            preprocessed_image=preprocessing(result_image,img)\n",
    "            \n",
    "            hog = Hog_descriptor(preprocessed_image, cell_size=4, bin_size=9)\n",
    "            vector, image = hog.extract()\n",
    "            vec = np.array(vector)\n",
    "            hog_features.append(vec.flatten())\n",
    "            data.append(label)\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "for label in arr:\n",
    "    dirList = glob.glob(\"../Dataset_0-5/Women/\"+str(label)+\"/*.jpg\")\n",
    "    \n",
    "    for img_path in dirList:\n",
    "        try:\n",
    "            im= cv2.imread(img_path)\n",
    "            img = cv2.resize(im, (256,256))\n",
    "            result_image=shadow_removalDialate(img)\n",
    "            preprocessed_image=preprocessing(result_image,img)\n",
    "            \n",
    "            hog = Hog_descriptor(preprocessed_image, cell_size=4, bin_size=9)\n",
    "            vector, image = hog.extract()\n",
    "            vec = np.array(vector)\n",
    "            hog_features.append(vec.flatten())\n",
    "            data.append(label)\n",
    "\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/models3']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(hog_features,data, test_size = 0.2)\n",
    "classifier=SVC(kernel=\"linear\", random_state=6)\n",
    "classifier.fit(train_x,train_y)\n",
    "joblib.dump(classifier, \"model/models3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.7671232876712328\n",
      "Precision=  0.7671103413948781\n",
      "Recall=  0.7671232876712328\n",
      "F1 Score=  0.7661056170293966\n",
      "Confusion Matrix=  [[50  0  0  1  1  1]\n",
      " [ 0 59  5  1  0  2]\n",
      " [ 5  5 29  9  3  1]\n",
      " [ 1  2  6 37  8  3]\n",
      " [ 1  1  3 10 46  2]\n",
      " [ 2  1  4  4  3 59]]\n",
      "Classification Report=                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89        53\n",
      "           1       0.87      0.88      0.87        67\n",
      "           2       0.62      0.56      0.59        52\n",
      "           3       0.60      0.65      0.62        57\n",
      "           4       0.75      0.73      0.74        63\n",
      "           5       0.87      0.81      0.84        73\n",
      "\n",
      "    accuracy                           0.77       365\n",
      "   macro avg       0.76      0.76      0.76       365\n",
      "weighted avg       0.77      0.77      0.77       365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction=classifier.predict(test_x)\n",
    "print(\"Accuracy= \",metrics.accuracy_score(prediction, test_y))\n",
    "print(\"Precision= \",metrics.precision_score(prediction, test_y, average='weighted'))\n",
    "print(\"Recall= \",metrics.recall_score(prediction, test_y, average='weighted'))\n",
    "print(\"F1 Score= \",metrics.f1_score(prediction, test_y, average='weighted'))\n",
    "print(\"Confusion Matrix= \",metrics.confusion_matrix(prediction, test_y))\n",
    "print(\"Classification Report= \",metrics.classification_report(prediction, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for i in range(len(hog_features)):\n",
    "        # Write one row at a time, with the label in the first column\n",
    "        row = [data[i]] + list(hog_features[i])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "orientations = 8\n",
    "pixels_per_cell = (16, 16)\n",
    "cells_per_block = (1, 1)\n",
    "visualize = False\n",
    "image = cv2.imread('../Dataset_0-5/men/1/1_men (9).JPG')\n",
    "image = cv2.resize(img, (256, 256))\n",
    "fd = hog(image, orientations=orientations, pixels_per_cell=pixels_per_cell,\n",
    "            cells_per_block=cells_per_block, visualize=visualize, channel_axis=-1)\n",
    "\n",
    "fd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "arr = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "data=[]\n",
    "hog_features = []\n",
    "lower_blue = np.array([0, 0, 65])\n",
    "upper_blue = np.array([20, 255, 255])\n",
    "\n",
    "for label in arr:\n",
    "    dirList = glob.glob(\"../Dataset_0-5/men/\"+str(label)+\"/*.jpg\")\n",
    "    \n",
    "    for img_path in dirList:\n",
    "        try:\n",
    "            im= cv2.imread(img_path)\n",
    "            img = cv2.resize(im, (256,256))\n",
    "\n",
    "            result_image=shadow_removalDialate(img)\n",
    "            preprocessed_image=preprocessing(result_image,img)\n",
    "            \n",
    "            # hog = Hog_descriptor(preprocessed_image, cell_size=4, bin_size=9)\n",
    "            # Compute HOG features\n",
    "            # fd = hog(preprocessed_image, orientations=orientations, pixels_per_cell=pixels_per_cell,cells_per_block=cells_per_block, visualize=visualize, channel_axis=-1)\n",
    "            fd = ft.hog(preprocessed_image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1),visualize=False)\n",
    "            # vector, image = hog.extract()\n",
    "            hog_features.append(fd)\n",
    "            data.append(label)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1047, 2048)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(hog_features).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img2 = cv2.imread()\n",
    "im= cv2.imread('../Dataset_0-5/men/1/1_men (2).JPG')\n",
    "img = cv2.resize(im, (256,256))\n",
    "\n",
    "result_image=shadow_removalDialate(img)\n",
    "preprocessed_image=preprocessing(result_image,img)\n",
    "\n",
    "    # Compute HOG features\n",
    "fd = ft.hog(preprocessed_image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1),visualize=False)\n",
    "# vector, image = hog.extract()\n",
    "np.array(fd).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "arr = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "for label in arr:\n",
    "    dirList = glob.glob(\"../Dataset_0-5/Women/\"+str(label)+\"/*.jpg\")\n",
    "    \n",
    "    for img_path in dirList:\n",
    "        try:\n",
    "            im= cv2.imread(img_path)\n",
    "            img = cv2.resize(im, (256,256))\n",
    "\n",
    "            result_image=shadow_removalDialate(img)\n",
    "            preprocessed_image=preprocessing(result_image,img)\n",
    "            \n",
    "            # hog = Hog_descriptor(preprocessed_image, cell_size=4, bin_size=9)\n",
    "            # Compute HOG features\n",
    "            fd = ft.hog(preprocessed_image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1),visualize=False)\n",
    "            # vector, image = hog.extract()\n",
    "            hog_features.append(fd)\n",
    "            data.append(label)\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 2048)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(hog_features).shape\n",
    "# fghffh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/models3']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(hog_features,data, test_size = 0.2)\n",
    "classifier=SVC(kernel=\"poly\", random_state=6)\n",
    "classifier.fit(train_x,train_y)\n",
    "joblib.dump(classifier, \"model/models3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.852054794520548\n",
      "Precision=  0.8570366507089279\n",
      "Recall=  0.852054794520548\n",
      "F1 Score=  0.8536176244235644\n",
      "Confusion Matrix=  [[56  0  0  0  0  0]\n",
      " [ 0 46  6  0  0  0]\n",
      " [ 0  0 41  7  3  1]\n",
      " [ 1  0  8 43  7  1]\n",
      " [ 1  0  1 11 53  2]\n",
      " [ 0  0  1  2  2 72]]\n",
      "Classification Report=                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        56\n",
      "           1       1.00      0.88      0.94        52\n",
      "           2       0.72      0.79      0.75        52\n",
      "           3       0.68      0.72      0.70        60\n",
      "           4       0.82      0.78      0.80        68\n",
      "           5       0.95      0.94      0.94        77\n",
      "\n",
      "    accuracy                           0.85       365\n",
      "   macro avg       0.86      0.85      0.85       365\n",
      "weighted avg       0.86      0.85      0.85       365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction=classifier.predict(test_x)\n",
    "print(\"Accuracy= \",metrics.accuracy_score(prediction, test_y))\n",
    "print(\"Precision= \",metrics.precision_score(prediction, test_y, average='weighted'))\n",
    "print(\"Recall= \",metrics.recall_score(prediction, test_y, average='weighted'))\n",
    "print(\"F1 Score= \",metrics.f1_score(prediction, test_y, average='weighted'))\n",
    "print(\"Confusion Matrix= \",metrics.confusion_matrix(prediction, test_y))\n",
    "print(\"Classification Report= \",metrics.classification_report(prediction, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
